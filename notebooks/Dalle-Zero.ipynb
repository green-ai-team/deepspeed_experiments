{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804badd9-cd4c-4da8-82aa-d14851760824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae90384-735c-4080-86c3-ef8e0a854825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook DALLE-DeepSpeed.ipynb to script\n",
      "[NbConvertApp] Writing 18573 bytes to DALLE-DeepSpeed.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script DALLE-DeepSpeed.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1710af-6332-4af0-b46f-2a077b73c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv DALLE-DeepSpeed.py ../scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "760b98c1-ca4d-47a8-8782-095444770ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import randint, choice\n",
    "import time\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import wandb  # Quit early if user doesn't have wandb installed.\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dalle_pytorch import DiscreteVAE, DALLE\n",
    "from dalle_pytorch import distributed_utils\n",
    "# from dalle_pytorch.loader import TextImageDataset\n",
    "from dalle_pytorch.tokenizer import tokenizer\n",
    "\n",
    "# libraries needed for webdataset support\n",
    "from torchvision import transforms as T\n",
    "import PIL\n",
    "from io import BytesIO\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032ea391-075d-41ff-91de-843977328b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19d4041b-145a-4a02-b91c-1f5fbd806a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def get_trainable_params(model):\n",
    "    return [params for params in model.parameters() if params.requires_grad]\n",
    "\n",
    "def cp_path_to_dir(cp_path, tag):\n",
    "    \"\"\"Convert a checkpoint path to a directory with `tag` inserted.\n",
    "    If `cp_path` is already a directory, return it unchanged.\n",
    "    \"\"\"\n",
    "    if not isinstance(cp_path, Path):\n",
    "        cp_path = Path(cp_path)\n",
    "    if cp_path.is_dir():\n",
    "        return cp_path\n",
    "    path_sans_extension = cp_path.parent / cp_path.stem\n",
    "    cp_dir = Path(f'{path_sans_extension}-{tag}-cp')\n",
    "    return cp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d857fce9-941e-4327-bd2f-12e81e0998b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEBDATASET_IMAGE_TEXT_COLUMNS = tuple(args.wds.split(','))\n",
    "# ENABLE_WEBDATASET = True if len(WEBDATASET_IMAGE_TEXT_COLUMNS) == 2 else False\n",
    "ENABLE_WEBDATASET = False\n",
    "\n",
    "DALLE_OUTPUT_FILE_NAME = \"../models/dalle-birds-deepspeed.pt\"\n",
    "\n",
    "VAE_PATH = \"../models/vae-birds-final.pt\"\n",
    "# VQGAN_MODEL_PATH = args.vqgan_model_path\n",
    "# VQGAN_CONFIG_PATH = args.vqgan_config_path\n",
    "# DALLE_PATH = args.dalle_path\n",
    "# RESUME = exists(DALLE_PATH)\n",
    "RESUME = False\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "GRAD_CLIP_NORM = 0.5\n",
    "LR_DECAY = False\n",
    "SAVE_EVERY_N_STEPS = 3000\n",
    "KEEP_N_CHECKPOINTS = None\n",
    "\n",
    "MODEL_DIM = 512\n",
    "TEXT_SEQ_LEN = 256\n",
    "DEPTH = 2\n",
    "HEADS = 4\n",
    "DIM_HEAD = 64\n",
    "REVERSIBLE = True\n",
    "LOSS_IMG_WEIGHT = 7\n",
    "FF_DROPOUT = 0.0\n",
    "ATTN_DROPOUT = 0.0\n",
    "STABLE = False\n",
    "SHIFT_TOKENS = True\n",
    "ROTARY_EMB = True\n",
    "FP16 = False\n",
    "\n",
    "# ATTN_TYPES = tuple(args.attn_types.split(','))\n",
    "ATTN_TYPES = None\n",
    "\n",
    "DEEPSPEED_CP_AUX_FILENAME = 'aux_dalle-birds-deepspeed.pt'\n",
    "\n",
    "IMAGE_FOLDER = '../data/CUB_200_2011/images'\n",
    "TEXT_FOLDER = '../data/birds/text_c10'\n",
    "\n",
    "RESIZE_RATIO = 0.75\n",
    "TRUNCATE_CAPTIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457b41e6-cd07-4d26-b7ab-932d2082c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(IMAGE_FOLDER).exists(), f'The path {IMAGE_FOLDER} was not found.'\n",
    "assert Path(TEXT_FOLDER).exists(), f'The path {TEXT_FOLDER} was not found.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2531cb6f-c16f-45ab-b512-5050dcdc6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "args = AttrDict()\n",
    "args.deepspeed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22f2c53a-50bf-476b-8205-47d7f6edcace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_env = [\"RANK\", \"WORLD_SIZE\", \"MASTER_ADDR\", \"MASTER_PORT\", \"LOCAL_RANK\"]\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = \"6006\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "list(map(lambda v: v in os.environ, required_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "667678e6-26f6-4ad6-a19d-05a2c590951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DeepSpeed for distributed execution\n"
     ]
    }
   ],
   "source": [
    "distr_backend = distributed_utils.set_backend_from_args(args)\n",
    "distr_backend.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d70cc22a-96f0-4ac6-9e7d-006bbfb52915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using_deepspeed = \\\n",
    "    distributed_utils.using_backend(distributed_utils.DeepSpeedBackend)\n",
    "using_deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b61b219-cc33-4c44-b514-ad0061090eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_path = Path(VAE_PATH)\n",
    "assert vae_path.exists(), 'VAE model file does not exist'\n",
    "assert not vae_path.is_dir(), \\\n",
    "    ('Cannot load VAE model from directory; please use a '\n",
    "     'standard *.pt checkpoint. '\n",
    "     'Currently, merging a DeepSpeed-partitioned VAE into a DALLE '\n",
    "     'model is not supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcf36b9c-3e2f-48c9-a047-456a903d815b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_obj = torch.load(str(vae_path))\n",
    "\n",
    "vae_params, weights = loaded_obj['hparams'], loaded_obj['weights']\n",
    "\n",
    "vae = DiscreteVAE(**vae_params)\n",
    "vae.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e747f87f-277a-4b09-9a56-5d46d83f479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = vae.image_size\n",
    "\n",
    "dalle_params = dict(\n",
    "    num_text_tokens=tokenizer.vocab_size,\n",
    "    text_seq_len=TEXT_SEQ_LEN,\n",
    "    dim=MODEL_DIM,\n",
    "    depth=DEPTH,\n",
    "    heads=HEADS,\n",
    "    dim_head=DIM_HEAD,\n",
    "    reversible=REVERSIBLE,\n",
    "    loss_img_weight=LOSS_IMG_WEIGHT,\n",
    "    attn_types=ATTN_TYPES,\n",
    "    ff_dropout=FF_DROPOUT,\n",
    "    attn_dropout=ATTN_DROPOUT,\n",
    "    stable=STABLE,\n",
    "    shift_tokens=SHIFT_TOKENS,\n",
    "    rotary_emb=ROTARY_EMB,\n",
    ")\n",
    "resume_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e9dcff7-d58e-44b8-b05b-5f997ac1ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_weight(model):\n",
    "    group_decay, group_no_decay = [], []\n",
    "    for params in model.named_parameters():\n",
    "        if 'transformer' in params[0]:\n",
    "            if 'bias' in params[0] or 'norm' in params[0]:\n",
    "                group_no_decay.append(params[1])\n",
    "                continue\n",
    "        group_decay.append(params[1])\n",
    "\n",
    "    assert len(list(model.parameters())) == len(group_decay) + len(group_no_decay)\n",
    "    groups = [dict(params=group_decay), dict(params=group_no_decay, weight_decay=.0)]\n",
    "    return groups\n",
    "\n",
    "def imagetransform(b):\n",
    "    return Image.open(BytesIO(b))\n",
    "\n",
    "def tokenize(s):\n",
    "    return tokenizer.tokenize(\n",
    "        s.decode('utf-8'),\n",
    "        TEXT_SEQ_LEN,\n",
    "        truncate_text=args.truncate_captions).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2787e582-81c3-48df-bc4d-904f4fe0a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_shuffle = not distributed_utils.using_backend(distributed_utils.HorovodBackend)\n",
    "is_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e5ce3f4-6d69-4f24-ab49-096f33416ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepreproc = T.Compose([\n",
    "            T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "            T.RandomResizedCrop(IMAGE_SIZE, scale = (RESIZE_RATIO, 1.), ratio = (1., 1.)),\n",
    "            T.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69926b0f-f027-4915-8fe1-35ef63203a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11789 image-text pairs found for training\n"
     ]
    }
   ],
   "source": [
    "class TextImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 image_folder,\n",
    "                 text_folder,\n",
    "                 text_len=256,\n",
    "                 image_size=128,\n",
    "                 truncate_captions=False,\n",
    "                 resize_ratio=0.75,\n",
    "                 tokenizer=None,\n",
    "                 shuffle=False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        @param folder: Folder containing images and text files matched by their paths' respective \"stem\"\n",
    "        @param truncate_captions: Rather than throw an exception, captions which are too long will be truncated.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.shuffle = shuffle\n",
    "        image_path = Path(image_folder)\n",
    "        text_path = Path(text_folder)\n",
    "\n",
    "        text_files = [*text_path.glob('**/*.txt')]\n",
    "        image_files = [\n",
    "            *image_path.glob('**/*.png'), *image_path.glob('**/*.jpg'),\n",
    "            *image_path.glob('**/*.jpeg'), *image_path.glob('**/*.bmp')\n",
    "        ]\n",
    "\n",
    "        text_files = {text_file.stem: text_file for text_file in text_files}\n",
    "        image_files = {image_file.stem: image_file for image_file in image_files}\n",
    "\n",
    "        keys = (image_files.keys() & text_files.keys())\n",
    "\n",
    "        self.keys = list(keys)\n",
    "        self.text_files = {k: v for k, v in text_files.items() if k in keys}\n",
    "        self.image_files = {k: v for k, v in image_files.items() if k in keys}\n",
    "        self.text_len = text_len\n",
    "        self.truncate_captions = truncate_captions\n",
    "        self.resize_ratio = resize_ratio\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = T.Compose([\n",
    "            T.Lambda(lambda img: img.convert('RGB')\n",
    "            if img.mode != 'RGB' else img),\n",
    "            T.RandomResizedCrop(image_size,\n",
    "                                scale=(self.resize_ratio, 1.),\n",
    "                                ratio=(1., 1.)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def random_sample(self):\n",
    "        return self.__getitem__(randint(0, self.__len__() - 1))\n",
    "\n",
    "    def sequential_sample(self, ind):\n",
    "        if ind >= self.__len__() - 1:\n",
    "            return self.__getitem__(0)\n",
    "        return self.__getitem__(ind + 1)\n",
    "\n",
    "    def skip_sample(self, ind):\n",
    "        if self.shuffle:\n",
    "            return self.random_sample()\n",
    "        return self.sequential_sample(ind=ind)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        key = self.keys[ind]\n",
    "\n",
    "        text_file = self.text_files[key]\n",
    "        image_file = self.image_files[key]\n",
    "\n",
    "        descriptions = text_file.read_text().split('\\n')\n",
    "        descriptions = list(filter(lambda t: len(t) > 0, descriptions))\n",
    "        try:\n",
    "            description = choice(descriptions)\n",
    "        except IndexError as zero_captions_in_file_ex:\n",
    "            print(f\"An exception occurred trying to load file {text_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "\n",
    "        tokenized_text = self.tokenizer.tokenize(\n",
    "            description,\n",
    "            self.text_len,\n",
    "            truncate_text=self.truncate_captions\n",
    "        ).squeeze(0)\n",
    "        try:\n",
    "            image_tensor = self.image_transform(PIL.Image.open(image_file))\n",
    "        except (PIL.UnidentifiedImageError, OSError) as corrupt_image_exceptions:\n",
    "            print(f\"An exception occurred trying to load file {image_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "\n",
    "        # Success\n",
    "        return tokenized_text, image_tensor\n",
    "    \n",
    "ds = TextImageDataset(\n",
    "        image_folder=IMAGE_FOLDER,\n",
    "        text_folder=TEXT_FOLDER,\n",
    "        text_len=TEXT_SEQ_LEN,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        resize_ratio=RESIZE_RATIO,\n",
    "        truncate_captions=TRUNCATE_CAPTIONS,\n",
    "        tokenizer=tokenizer,\n",
    "        shuffle=is_shuffle,\n",
    "    )\n",
    "assert len(ds) > 0, 'dataset is empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3301c32c-ae3d-4a43-87c8-676147e1a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11789 image-text pairs found for training\n"
     ]
    }
   ],
   "source": [
    "if distr_backend.is_root_worker():\n",
    "    if not ENABLE_WEBDATASET:\n",
    "        print(f'{len(ds)} image-text pairs found for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a698c9b-56c5-4379-9ba8-93083f8e813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_shuffle:\n",
    "    data_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        ds,\n",
    "        num_replicas=distr_backend.get_world_size(),\n",
    "        rank=distr_backend.get_rank()\n",
    "    )\n",
    "else:\n",
    "    data_sampler = None\n",
    "data_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68def296-7a71-48e1-8464-aff6c1501452",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=is_shuffle, drop_last=True, sampler=data_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5c2ca00-a8fd-49dc-90d4-f8cd2083a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dalle = DALLE(vae=vae, **dalle_params)\n",
    "if not using_deepspeed:\n",
    "    if args.fp16:\n",
    "        dalle = dalle.half()\n",
    "    dalle = dalle.cuda()\n",
    "\n",
    "if RESUME and not using_deepspeed:\n",
    "    dalle.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "481fba4c-d628-429d-a900-8a76b0c8b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(get_trainable_params(dalle), lr=LEARNING_RATE)\n",
    "if RESUME and opt_state:\n",
    "    opt.load_state_dict(opt_state)\n",
    "\n",
    "if LR_DECAY:\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        opt,\n",
    "        mode=\"min\",\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        cooldown=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=True,\n",
    "    )\n",
    "    if RESUME and scheduler_state:\n",
    "        scheduler.load_state_dict(scheduler_state)\n",
    "else:\n",
    "    scheduler = None\n",
    "    \n",
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1e21597-3ba2-4583-87e9-10c78a7a6798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdarayavaus\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/darayavaus/dalle/runs/1xxkzjru\" target=\"_blank\">prime-fog-6</a></strong> to <a href=\"https://wandb.ai/darayavaus/dalle\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if distr_backend.is_root_worker():\n",
    "    # experiment tracker\n",
    "\n",
    "    model_config = dict(\n",
    "        depth=DEPTH,\n",
    "        heads=HEADS,\n",
    "        dim_head=DIM_HEAD\n",
    "    )\n",
    "\n",
    "    run = wandb.init(\n",
    "        project='dalle',\n",
    "        entity='darayavaus',\n",
    "        resume=RESUME,\n",
    "        config=model_config,\n",
    "    )\n",
    "    run.name = f'training-transformer-{run.id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "880321be-8c85-4db2-ba6a-b750e5c3de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints made with DeepSpeed ZeRO Stages 2 and 3 will be stored in deepspeed checkpoint folder\n",
      "As such, they will require DeepSpeed as a dependency in order to resume from or generate with.\n",
      "See the deespeed conversion script for details on how to convert your ZeRO stage 2/3 checkpoint to a single file.\n",
      "If using a single GPU, consider running with apex automatic mixed precision instead for a similar speedup to ZeRO.\n"
     ]
    }
   ],
   "source": [
    "distr_backend.check_batch_size(BATCH_SIZE)\n",
    "deepspeed_config = {\n",
    "    'train_batch_size': BATCH_SIZE,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'gradient_clipping': GRAD_CLIP_NORM,\n",
    "    'fp16': {\n",
    "        'enabled': FP16,\n",
    "    },\n",
    "    'amp': {\n",
    "        'enabled': False,\n",
    "        'opt_level': 'O1',\n",
    "    },\n",
    "    \"flops_profiler\": {\n",
    "        \"enabled\": False,\n",
    "        \"profile_step\": 200,\n",
    "        \"module_depth\": -1,\n",
    "        \"top_modules\": 1,\n",
    "        \"detailed\": True,\n",
    "        \"output_file\": None # TODO Can't get this to work.\n",
    "    },\n",
    "#     \"zero_optimization\": {\n",
    "#         \"stage\": 3,\n",
    "#         # Offload the model parameters If you have an nvme drive - you should use the nvme option.\n",
    "#         # Otherwise, use 'cpu' and remove the `nvme_path` line\n",
    "#         \"offload_param\": {\n",
    "#             \"device\": \"nvme\",\n",
    "#             \"nvme_path\": \"/path/to/nvme/folder\",\n",
    "#         },\n",
    "#         # Offload the optimizer of choice. If you have an nvme drive - you should use the nvme option.\n",
    "#         # Otherwise, use 'cpu' and remove the `nvme_path` line\n",
    "#         \"offload_optimizer\": {\n",
    "#             \"device\": \"nvme\", # options are 'none', 'cpu', 'nvme'\n",
    "#             \"nvme_path\": \"/path/to/nvme/folder\",\n",
    "#         },\n",
    "#     },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\", \n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "if deepspeed_config.get('zero_optimization', {}).get('stage', 0) >= 2:\n",
    "    print(f\"Checkpoints made with DeepSpeed ZeRO Stages 2 and 3 will be stored in deepspeed checkpoint folder\")\n",
    "    print(f\"As such, they will require DeepSpeed as a dependency in order to resume from or generate with.\")\n",
    "    print(\"See the deespeed conversion script for details on how to convert your ZeRO stage 2/3 checkpoint to a single file.\")\n",
    "    print(\"If using a single GPU, consider running with apex automatic mixed precision instead for a similar speedup to ZeRO.\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b44193-8374-491b-a543-c93cc5f25856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-11 04:43:28,866] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.4, git-hash=unknown, git-branch=unknown\n",
      "[2021-10-11 04:43:28,917] [INFO] [engine.py:204:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "[2021-10-11 04:43:28,918] [INFO] [engine.py:848:_configure_optimizer] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2021-10-11 04:43:28,918] [INFO] [engine.py:854:_configure_optimizer] Using client Optimizer as basic optimizer\n",
      "[2021-10-11 04:43:28,919] [INFO] [engine.py:870:_configure_optimizer] DeepSpeed Basic Optimizer = Adam\n",
      "[2021-10-11 04:43:28,919] [INFO] [utils.py:43:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2021-10-11 04:43:28,920] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
      "Initializing ZeRO Stage 3\n",
      "[2021-10-11 04:43:28,920] [INFO] [stage3.py:638:__init__] Reduce bucket size 500000000\n",
      "[2021-10-11 04:43:28,920] [INFO] [stage3.py:639:__init__] Allgather bucket size 50000000\n",
      "Using /beegfs/home/d.cherniuk/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00334930419921875 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-11 04:43:30,475] [INFO] [stage3.py:831:__init__] optimizer state initialized\n",
      "[2021-10-11 04:43:30,492] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2021-10-11 04:43:30,492] [INFO] [engine.py:596:_configure_lr_scheduler] DeepSpeed using client LR scheduler\n",
      "[2021-10-11 04:43:30,493] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2021-10-11 04:43:30,493] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[(0.9, 0.999)]\n",
      "[2021-10-11 04:43:30,494] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "[2021-10-11 04:43:30,495] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-10-11 04:43:30,496] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-10-11 04:43:30,496] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-10-11 04:43:30,497] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-10-11 04:43:30,497] [INFO] [config.py:944:print]   amp_params ................... {'opt_level': 'O1'}\n",
      "[2021-10-11 04:43:30,497] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-10-11 04:43:30,498] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-10-11 04:43:30,498] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-10-11 04:43:30,499] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-10-11 04:43:30,499] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-10-11 04:43:30,499] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-10-11 04:43:30,500] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-10-11 04:43:30,500] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... None\n",
      "[2021-10-11 04:43:30,500] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-10-11 04:43:30,501] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-10-11 04:43:30,501] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-10-11 04:43:30,502] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-10-11 04:43:30,502] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-10-11 04:43:30,502] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-10-11 04:43:30,503] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-10-11 04:43:30,503] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-10-11 04:43:30,504] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-10-11 04:43:30,504] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 200, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-10-11 04:43:30,505] [INFO] [config.py:944:print]   fp16_enabled ................. False\n",
      "[2021-10-11 04:43:30,505] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-10-11 04:43:30,505] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-10-11 04:43:30,506] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-10-11 04:43:30,506] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
      "[2021-10-11 04:43:30,507] [INFO] [config.py:944:print]   gradient_clipping ............ 0.5\n",
      "[2021-10-11 04:43:30,507] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-10-11 04:43:30,507] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 4294967296\n",
      "[2021-10-11 04:43:30,508] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-10-11 04:43:30,508] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-10-11 04:43:30,509] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-10-11 04:43:30,509] [INFO] [config.py:944:print]   optimizer_name ............... None\n",
      "[2021-10-11 04:43:30,509] [INFO] [config.py:944:print]   optimizer_params ............. None\n",
      "[2021-10-11 04:43:30,510] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-10-11 04:43:30,510] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-10-11 04:43:30,511] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-10-11 04:43:30,511] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-10-11 04:43:30,512] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-10-11 04:43:30,512] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-10-11 04:43:30,512] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-10-11 04:43:30,513] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-10-11 04:43:30,513] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-10-11 04:43:30,514] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-10-11 04:43:30,514] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-10-11 04:43:30,514] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-10-11 04:43:30,515] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-10-11 04:43:30,515] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-10-11 04:43:30,516] [INFO] [config.py:944:print]   scheduler_name ............... None\n",
      "[2021-10-11 04:43:30,516] [INFO] [config.py:944:print]   scheduler_params ............. None\n",
      "[2021-10-11 04:43:30,516] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-10-11 04:43:30,517] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-10-11 04:43:30,517] [INFO] [config.py:944:print]   steps_per_print .............. 10\n",
      "[2021-10-11 04:43:30,518] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-10-11 04:43:30,518] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-10-11 04:43:30,518] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-10-11 04:43:30,519] [INFO] [config.py:944:print]   train_batch_size ............. 4\n",
      "[2021-10-11 04:43:30,519] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-10-11 04:43:30,520] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-10-11 04:43:30,520] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-10-11 04:43:30,520] [INFO] [config.py:944:print]   world_size ................... 1\n",
      "[2021-10-11 04:43:30,521] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
      "[2021-10-11 04:43:30,522] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 3, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": false, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false, \n",
      "        \"pipeline\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-10-11 04:43:30,522] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-10-11 04:43:30,522] [INFO] [config.py:944:print]   zero_optimization_stage ...... 3\n",
      "[2021-10-11 04:43:30,523] [INFO] [config.py:946:print]   json = {\n",
      "    \"train_batch_size\": 4, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 0.5, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"amp\": {\n",
      "        \"enabled\": false, \n",
      "        \"opt_level\": \"O1\"\n",
      "    }, \n",
      "    \"flops_profiler\": {\n",
      "        \"enabled\": false, \n",
      "        \"profile_step\": 200, \n",
      "        \"module_depth\": -1, \n",
      "        \"top_modules\": 1, \n",
      "        \"detailed\": true, \n",
      "        \"output_file\": null\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Using /beegfs/home/d.cherniuk/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.007081270217895508 seconds\n"
     ]
    }
   ],
   "source": [
    "(distr_dalle, distr_opt, distr_dl, distr_scheduler) = distr_backend.distribute(\n",
    "    args=args,\n",
    "    model=dalle,\n",
    "    optimizer=opt,\n",
    "    model_parameters=get_trainable_params(dalle),\n",
    "    training_data=(\n",
    "        (None if ENABLE_WEBDATASET else ds)\n",
    "        if using_deepspeed\n",
    "        else dl\n",
    "    ),\n",
    "    # Do not pass the LR scheduler to DeepSpeed so we can manually\n",
    "    # advance it.\n",
    "    lr_scheduler=scheduler if LR_DECAY and not using_deepspeed else None,\n",
    "    config_params=deepspeed_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13a9609f-1b90-46c0-9faa-3aa1372017dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefer scheduler in `deepspeed_config`.\n",
    "if LR_DECAY and distr_scheduler is None:\n",
    "    distr_scheduler = scheduler\n",
    "avoid_model_calls = using_deepspeed and FP16\n",
    "\n",
    "if RESUME and using_deepspeed:\n",
    "    distr_dalle.load_checkpoint(str(cp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e808c10-ee71-421e-9a80-1cd535dbfcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path, epoch=0):\n",
    "    save_obj = {\n",
    "        'hparams': dalle_params,\n",
    "        'vae_params': vae_params,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    if using_deepspeed:\n",
    "        cp_dir = cp_path_to_dir(path, 'ds')\n",
    "\n",
    "        if KEEP_N_CHECKPOINTS is not None and distr_backend.is_root_worker():\n",
    "            checkpoints = sorted(glob(str(cp_dir / \"global*\")), key=os.path.getmtime, reverse=True)\n",
    "            for checkpoint in checkpoints[KEEP_N_CHECKPOINTS:]:\n",
    "                shutil.rmtree(checkpoint)\n",
    "\n",
    "        distr_dalle.save_checkpoint(cp_dir, client_state=save_obj)\n",
    "\n",
    "        if not distr_backend.is_root_worker():\n",
    "            return\n",
    "\n",
    "        # Save auxiliary values so we can reuse the standard routine\n",
    "        # for loading.\n",
    "        save_obj = {\n",
    "            **save_obj,\n",
    "            # Save a nonsense value that directs the user to\n",
    "            # further help.\n",
    "            'weights': (\n",
    "                'To get a working standard checkpoint, '\n",
    "                'look into consolidating DeepSpeed checkpoints.'\n",
    "            ),\n",
    "        }\n",
    "        torch.save(save_obj, str(cp_dir / DEEPSPEED_CP_AUX_FILENAME))\n",
    "        if deepspeed_config.get('zero_optimization', {}).get('stage', 0) >= 2: # see https://github.com/lucidrains/DALLE-pytorch/wiki/DeepSpeed-Checkpoints\n",
    "            return\n",
    "\n",
    "    if not distr_backend.is_root_worker():\n",
    "        return\n",
    "\n",
    "    save_obj = {\n",
    "        **save_obj,\n",
    "        'weights': dalle.state_dict(),\n",
    "        'opt_state': opt.state_dict(),\n",
    "    }\n",
    "    save_obj['scheduler_state'] = (scheduler.state_dict() if scheduler else None)\n",
    "    torch.save(save_obj, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d66b573e-83ef-4129-aa9d-d394187205d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-11 04:49:45,300] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ../models/dalle-birds-deepspeed-ds-cp/global_step0/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "[2021-10-11 04:49:46,209] [INFO] [engine.py:2492:_save_zero_checkpoint] zero checkpoint saved ../models/dalle-birds-deepspeed-ds-cp/global_step0/zero_pp_rank_0_mp_rank_00_optim_states.pt\n"
     ]
    }
   ],
   "source": [
    "# Saves a checkpoint before training begins to fail early when mis-configured.\n",
    "# See https://github.com/lucidrains/DALLE-pytorch/wiki/DeepSpeed-Checkpoints\n",
    "save_model(DALLE_OUTPUT_FILE_NAME, epoch=resume_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "583e9311-ea17-4f53-abab-e77864962ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss - 9.397420883178711\n",
      "[2021-10-11 04:54:09,546] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ../models/dalle-birds-deepspeed-ds-cp/global_step1/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "[2021-10-11 04:54:10,491] [INFO] [engine.py:2492:_save_zero_checkpoint] zero checkpoint saved ../models/dalle-birds-deepspeed-ds-cp/global_step1/zero_pp_rank_0_mp_rank_00_optim_states.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.10 GiB (GPU 0; 10.76 GiB total capacity; 6.96 GiB already allocated; 187.44 MiB free; 9.44 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_212739/117741064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musing_deepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mdistr_dalle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mdistr_dalle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Gradients are automatically zeroed after the step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, allreduce_gradients, release_loss)\u001b[0m\n\u001b[1;32m   1406\u001b[0m             self.optimizer.is_gradient_accumulation_boundary = self.is_gradient_accumulation_boundary(\n\u001b[1;32m   1407\u001b[0m             )\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0;31m# AMP requires delaying unscale when inside gradient accumulation boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/runtime/zero/stage3.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m   2974\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipg_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2976\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2977\u001b[0m         '''Partitioning Parameters that were not partitioned\n\u001b[1;32m   2978\u001b[0m         \u001b[0mUsually\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0minput\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mscaled_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.10 GiB (GPU 0; 10.76 GiB total capacity; 6.96 GiB already allocated; 187.44 MiB free; 9.44 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(resume_epoch, EPOCHS):\n",
    "    if data_sampler:\n",
    "        data_sampler.set_epoch(epoch)\n",
    "    for i, (text, images) in enumerate((dl if ENABLE_WEBDATASET else distr_dl)):\n",
    "        if i % 10 == 0 and distr_backend.is_root_worker():\n",
    "            t = time.time()\n",
    "        if FP16:\n",
    "            images = images.half()\n",
    "        text, images = map(lambda t: t.cuda(), (text, images))\n",
    "\n",
    "        loss = distr_dalle(text, images, return_loss=True)\n",
    "\n",
    "        if using_deepspeed:\n",
    "            distr_dalle.backward(loss)\n",
    "            distr_dalle.step()\n",
    "            # Gradients are automatically zeroed after the step\n",
    "        else:\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(distr_dalle.parameters(), GRAD_CLIP_NORM)\n",
    "            distr_opt.step()\n",
    "            distr_opt.zero_grad()\n",
    "\n",
    "        # Collective loss, averaged\n",
    "        avg_loss = distr_backend.average_all(loss)\n",
    "\n",
    "        log = {}\n",
    "\n",
    "        if i % 10 == 0 and distr_backend.is_root_worker():\n",
    "            print(epoch, i, f'loss - {avg_loss.item()}')\n",
    "\n",
    "            log = {\n",
    "                **log,\n",
    "                'epoch': epoch,\n",
    "                'iter': i,\n",
    "                'loss': avg_loss.item()\n",
    "            }\n",
    "\n",
    "        if i % SAVE_EVERY_N_STEPS == 0:\n",
    "            save_model(DALLE_OUTPUT_FILE_NAME, epoch=epoch)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            if distr_backend.is_root_worker():\n",
    "                sample_text = text[:1]\n",
    "                token_list = sample_text.masked_select(sample_text != 0).tolist()\n",
    "                decoded_text = tokenizer.decode(token_list)\n",
    "\n",
    "                if not avoid_model_calls:\n",
    "                    # CUDA index errors when we don't guard this\n",
    "                    image = dalle.generate_images(text[:1], filter_thres=0.9)  # topk sampling at 0.9\n",
    "\n",
    "\n",
    "                log = {\n",
    "                    **log,\n",
    "                }\n",
    "                if not avoid_model_calls:\n",
    "                    log['image'] = wandb.Image(image, caption=decoded_text)\n",
    "\n",
    "        if i % 10 == 9 and distr_backend.is_root_worker():\n",
    "            sample_per_sec = BATCH_SIZE * 10 / (time.time() - t)\n",
    "            log[\"sample_per_sec\"] = sample_per_sec\n",
    "            print(epoch, i, f'sample_per_sec - {sample_per_sec}')\n",
    "\n",
    "#         if i == 201 and args.flops_profiler:\n",
    "#             raise StopIteration(\"Profiler has finished running. Stopping training early.\")\n",
    "\n",
    "        if distr_backend.is_root_worker():\n",
    "            wandb.log(log)\n",
    "\n",
    "    if LR_DECAY:\n",
    "        distr_scheduler.step(avg_loss)\n",
    "\n",
    "    save_model(DALLE_OUTPUT_FILE_NAME, epoch=epoch)\n",
    "    \n",
    "    if distr_backend.is_root_worker():\n",
    "        # save trained model to wandb as an artifact every epoch's end\n",
    "\n",
    "        model_artifact = wandb.Artifact('trained-dalle', type='model', metadata=dict(model_config))\n",
    "        model_artifact.add_file(DALLE_OUTPUT_FILE_NAME)\n",
    "        run.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d3871-4346-4474-8dd0-2fc33d5e45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(DALLE_OUTPUT_FILE_NAME, epoch=epoch)\n",
    "if distr_backend.is_root_worker():\n",
    "    wandb.save(DALLE_OUTPUT_FILE_NAME)\n",
    "    model_artifact = wandb.Artifact('trained-dalle', type='model', metadata=dict(model_config))\n",
    "    model_artifact.add_file(DALLE_OUTPUT_FILE_NAME)\n",
    "    run.log_artifact(model_artifact)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a49b9d-3180-4f9c-acf8-d8028f575b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_223665/2127913808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818dc78-c985-44f0-810f-935576a450c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark13",
   "language": "python",
   "name": "mark13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
